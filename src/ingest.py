import os
import shutil
import json
import gc  # åƒåœ¾å›æ”¶
from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.schema import Document 
from src.config import DATA_PATH, DB_PATH, EMBEDDING_MODEL, CHUNK_SIZE, CHUNK_OVERLAP

def create_vector_db():
    print("ğŸ“š æ­£åœ¨å»ºç«‹çŸ¥è­˜åº« (æ”¯æ´ PDF èˆ‡ JSON)...")
    
    if not os.path.exists(DATA_PATH):
        os.makedirs(DATA_PATH)
        print(f"âš ï¸ è«‹å°‡æª”æ¡ˆæ”¾å…¥ {DATA_PATH}")
        return

    documents = []

    # --- 1. è®€å– PDF ---
    pdf_files = [f for f in os.listdir(DATA_PATH) if f.endswith('.pdf')]
    if pdf_files:
        print(f"ğŸ“„ ç™¼ç¾ {len(pdf_files)} å€‹ PDFï¼Œæ­£åœ¨è®€å–...")
        loader = DirectoryLoader(DATA_PATH, glob="*.pdf", loader_cls=PyPDFLoader)
        try:
            pdf_docs = loader.load()
            documents.extend(pdf_docs)
        except Exception as e:
            print(f"âŒ è®€å– PDF æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    # --- 2. è®€å– JSON ---
    json_files = [f for f in os.listdir(DATA_PATH) if f.endswith('.json')]
    if json_files:
        print(f"ğŸ“‹ ç™¼ç¾ {len(json_files)} å€‹ JSONï¼Œæ­£åœ¨è®€å–...")
        for j_file in json_files:
            try:
                path = os.path.join(DATA_PATH, j_file)
                with open(path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # è½‰å­—ä¸²
                text_content = json.dumps(data, ensure_ascii=False, indent=2)
                
                doc = Document(
                    page_content=text_content,
                    metadata={"source": j_file, "page": 0}
                )
                documents.append(doc)
            except Exception as e:
                print(f"âŒ è®€å– JSON å¤±æ•— ({j_file}): {e}")

    # æª¢æŸ¥æœ‰ç„¡è³‡æ–™
    if not documents:
        print("âŒ data è³‡æ–™å¤¾ä¸­æ²’æœ‰å¯è®€å–çš„ PDF æˆ– JSONï¼")
        return

    # --- 3. åˆ‡åˆ†æ–‡å­— (é—œéµæ­¥é©Ÿï¼šå®šç¾© texts è®Šæ•¸) ---
    print(f"âœ‚ï¸ æ­£åœ¨åˆ‡åˆ† {len(documents)} ä»½æ–‡ä»¶...")
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE, 
        chunk_overlap=CHUNK_OVERLAP
    )
    
    # é€™è¡Œå°±æ˜¯ä¹‹å‰ç¼ºå°‘çš„ï¼šæŠŠ documents åˆ‡æˆ texts
    texts = text_splitter.split_documents(documents)
    print(f"ğŸ§© å…±åˆ‡åˆ†ç‚º {len(texts)} å€‹ç‰‡æ®µ")

    # --- 4. æ¸…ç†èˆŠè³‡æ–™åº« (å«åƒåœ¾å›æ”¶) ---
    
    # å¼·åˆ¶é‡‹æ”¾è¨˜æ†¶é«”ï¼Œé¿å…æª”æ¡ˆè¢«é–å®š
    gc.collect()

    if os.path.exists(DB_PATH):
        try:
            shutil.rmtree(DB_PATH)
            print("ğŸ—‘ï¸ å·²æ¸…é™¤èˆŠè³‡æ–™åº«")
        except PermissionError:
            print("âš ï¸ ç„¡æ³•åˆªé™¤èˆŠè³‡æ–™åº« (å¯èƒ½æ­£è¢«ä½”ç”¨)ï¼Œå°‡å˜—è©¦ç›´æ¥è¦†è“‹...")
        except Exception as e:
            print(f"âš ï¸ æ¸…é™¤è³‡æ–™åº«æ™‚é‡åˆ°å°å•é¡Œ: {e}")

    # --- 5. å»ºç«‹æ–°è³‡æ–™åº« ---
    print(f"ğŸš€ æ­£åœ¨å‘é‡åŒ–ä¸¦å¯«å…¥è³‡æ–™åº« (ä½¿ç”¨ {EMBEDDING_MODEL})...")
    embedding_func = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)
    
    try:
        Chroma.from_documents(
            documents=texts,  # é€™è£¡ç¾åœ¨æ‰¾å¾—åˆ° texts äº†ï¼
            embedding=embedding_func, 
            persist_directory=DB_PATH
        )
        print(f"âœ… çŸ¥è­˜åº«å»ºç«‹å®Œæˆï¼å„²å­˜æ–¼: {DB_PATH}")
    except Exception as e:
        print(f"âŒ å»ºç«‹è³‡æ–™åº«å¤±æ•—: {e}")

if __name__ == "__main__":
    create_vector_db()